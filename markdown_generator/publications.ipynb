{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publications markdown generator for academicpages\n",
    "\n",
    "Takes a TSV of publications with metadata and converts them for use with [academicpages.github.io](academicpages.github.io). This is an interactive Jupyter notebook ([see more info here](http://jupyter-notebook-beginner-guide.readthedocs.io/en/latest/what_is_jupyter.html)). The core python code is also in `publications.py`. Run either from the `markdown_generator` folder after replacing `publications.tsv` with one containing your data.\n",
    "\n",
    "TODO: Make this work with BibTex and other databases of citations, rather than Stuart's non-standard TSV format and citation style.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data format\n",
    "\n",
    "The TSV needs to have the following columns: pub_date, title, venue, excerpt, citation, site_url, and paper_url, with a header at the top. \n",
    "\n",
    "- `excerpt` and `pub_paper_url` can be blank, but the others must have values. \n",
    "- `pub_date` must be formatted as YYYY-MM-DD.\n",
    "- `url_slug` will be the descriptive part of the .md file and the permalink URL for the page about the paper. The .md file will be `YYYY-MM-DD-[url_slug].md` and the permalink will be `https://[yourdomain]/publications/YYYY-MM-DD-[url_slug]`\n",
    "\n",
    "This is how the raw file looks (it doesn't look pretty, use a spreadsheet or other program to edit and create)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pub_date\tstatus\tstatus2\ttitle\tvenue\texcerpt\tabstract\tcoauthors\tcitation\tcv_citation_authors\tcv_citation_other\turl_slug\tpub_paper_url\twp_paper_url\tslides_url\topt0_text\topt0_url\topt1_text\topt1_url\topt2_text\topt2_url\n",
      "26/12/2024\twork_in_progress\t\tInformational Experiment on Consumer's Perception of Central Bank Digital Currency as Liquidity Assets\t\t\t\tKohei Kawaguchi and Si Yuan Jin\t\"Dordal i Carreras, Marc, Kohei Kawaguchi and Si Yuan Jin. \"\"Informational Experiment on Consumer's Perception of Central Bank Digital Currency as Liquidity Assets.\"\"  <i>In Progress</i> (2024).\"\t\"Dordal i Carreras, Marc, Kohei Kawaguchi and Si Yuan Jin\"\t<i>In Progress</i> (2024).\tDKJ_info_pilot\t\t\t\t\t\t\t\t\t\n",
      "11/1/2024\twork_in_progress\t\tWhat Do We Learn From Reading Every FOMC Transcript?\t\t\t\t\"Olivier Coibion, Yuriy Gorodnichenko and Cooper Howes\"\t\"Coibion, Olivier, Marc Dordal i Carreras, Yuriy Gorodnichenko, and Cooper Howes. \"\"What Do We Learn From Reading Every FOMC Transcript?\"\"  <i>In Progress</i> (2024).\"\t\"Coibion, Olivier, Marc Dordal i Carreras, Yuriy Gorodnichenko, and Cooper Howes.\"\t<i>In Progress</i> (2024).\tCDGH_FOMC_transcript\t\t\t\t\t\t\t\t\t\n",
      "22/02/2025\tworking_paper\tsubmitted\tYield-Curve Control Policy under Inelastic Financial Markets\t\t\"We develop a New Keynesian framework that incorporates the term structure of financial markets, emphasizing the role of government and central bank balance sheet composition in monetary policy transmission. Our model accounts for microfounded market segmentation across asset classes and maturities based on finite and estimable asset demand elasticities. We show that unconventional policy interventions, such as large-scale asset purchase programs and yield-curve control policies, effectively stabilize the economy during normal periods and at the zero lower bound, albeit by extending ZLB episodes and reducing the efficacy of future short-term rate adjustments.\"\t\"We develop a New Keynesian framework that incorporates the term structure of financial markets, emphasizing the role of government and central bank balance sheet composition in monetary policy transmission. Our model accounts for microfounded market segmentation across asset classes and maturities based on finite and estimable asset demand elasticities. We show that unconventional policy interventions, such as large-scale asset purchase programs and yield-curve control policies, effectively stabilize the economy during normal periods and at the zero lower bound, albeit by extending ZLB episodes and reducing the efficacy of future short-term rate adjustments.\"\tSeung Joo Lee\t\"Joo Lee, Seung, and Marc Dordal i Carreras. \"\"Yield-Curve Control Policy under Inelastic Financial Markets.\"\"  <i>Working Paper</i> (2025).\"\t\"Joo Lee, Seung, and Marc Dordal i Carreras.\"\t<i>Working Paper</i> (2025).\tJD_term_structure_theory\t\thttp://marcdordal.github.io/files/WP_Term_Structure_Theory.pdf\thttp://marcdordal.github.io/files/slides_Term_Structure_Theory.pdf\t\t\t\t\t\t\n",
      "26/12/2024\tworking_paper\tsubmitted\tThe Spatial Transmission of US Banking Panics: Evidence from 1870-1929\t\t\"We study the propagation of localized banking panics across the United States, employing digitized state-level balance sheet data on the National Banks for the 1870-1929 period. Geographically localized panics result in the robust spillover outside the state borders where they originate, leading to moderately persistent credit contractions and the accumulation of liquid assets. We provide a tractable model illustrating a key trade-off: while interbank markets, e.g., the pyramidal reserve structure of the banking system during the National Banking Era, allow banks to access cheaper funding, they spread the effects of panics throughout the country as observed in the data.\"\t\"We study the propagation of localized banking panics across the United States, employing digitized state-level balance sheet data on the National Banks for the 1870-1929 period. Geographically localized panics result in the robust spillover outside the state borders where they originate, leading to moderately persistent credit contractions and the accumulation of liquid assets. We provide a tractable model illustrating a key trade-off: while interbank markets, e.g., the pyramidal reserve structure of the banking system during the National Banking Era, allow banks to access cheaper funding, they spread the effects of panics throughout the country as observed in the data.\"\tSeung Joo Lee\t\"Dordal i Carreras, Marc and Seung Joo Lee. \"\"The Spatial Transmission of US Banking Panics.\"\"  <i>Working Paper</i> (2023).\"\t\"Dordal i Carreras, Marc and Seung Joo Lee.\"\t<i>Working Paper</i> (2024).\tDJ_Bank_Panics\t\thttp://marcdordal.github.io/files/WP_US_Panics.pdf\thttp://marcdordal.github.io/files/slides_US_Panics.pdf\t\t\t\t\t\t\n",
      "22/02/2025\tworking_paper\trevise_resubmit\tConsumer Perceptions and Willingness to Adopt rCBDCs Before and After the e-HKD Pilot\tDistributed Ledger Technologies: Research and Practice\t\"This study explores public perceptions of retail central bank digital currency (rCBDC) adoption through a pilot e-HKD payment system in Hong Kong. Surveys conducted before and after participants used the prototype revealed initially positive attitudes, with perceptions shifting significantly after the experience, particularly regarding security, ease of use, and promotional features. The findings highlight the importance of consumer perceptions, their susceptibility to change through exposure, and the need for cautious interpretation of survey data in this area.\"\t\"This study investigates the public's perception of retail central bank digital currency (rCBDC) and identifies the factors influencing its adoption. Conducted in collaboration with a prominent bank in Hong Kong, this research involved a hands-on experience with a prototype payment system making using of an e-HKD, being an rCBDC which could be implemented in Hong Kong. Participants' opinions on rCBDCs were assessed through surveys conducted before and after their engagement with the e-HKD pilot. Initially, participants displayed a broadly positive attitude towards rCBDC, although no single factor emerged as a decisive influence on their adoption decision. However, the pilot experience statistically significantly altered perceptions, particularly regarding security, ease of payment, and promotional functions, thereby impacting their willingness to adopt rCBDC. This study underscores the importance of understanding consumer perceptions and suggests that these perceptions are subject to change through exposure to regulatory information campaigns, prototype experiences, and initial models. Consequently, the study recommends a cautious approach to interpreting the reliability of existing survey findings in this domain.\"\t\"Kohei Kawaguchi, Si Yuan Jin and Haicheng Guo\"\t\"Dordal i Carreras, Marc, Kohei Kawaguchi, Si Yuan Jin and Haicheng Guo. \"\"Consumer Perceptions and Willingness to Adopt rCBDCs Before and After the e-HKD Pilot.\"\"  <i>In Progress</i> (2024).\"\t\"Dordal i Carreras, Marc, Kohei Kawaguchi, Si Yuan Jin and Haicheng Guo\"\t<i>Working Paper</i> (2024).\tDKJG_eHKD_pilot\t\thttp://marcdordal.github.io/files/WP_rCBDC_Taste_and_Perception.pdf\t\t\t\t\t\t\t\n",
      "8/1/2024\tworking_paper\tsubmitted\tHigher-Order Forward Guidance\t\t\"This paper develops a business cycle model with endogenous financial volatility at the Zero Lower Bound (ZLB), highlighting forward guidance as a key mechanism for coordinating market behavior and improving welfare. We show that central banks can reduce excess volatility by credibly pledging future stabilization, or alternatively, by withholding such pledges to direct the economy toward favorable outcomes with lower volatility, revealing a trade-off. We also find that partial uncertainty about future policy dominates strict commitments. Finally, fiscal measures that promote risky asset investments can boost economic activity at the ZLB by increasing aggregate household financial wealth.\"\t\"This paper presents a model of the business cycle that incorporates financial markets and endogenous financial volatility at the Zero Lower Bound (ZLB). Within this framework, forward guidance is identified as a crucial mechanism for coordinating the actions of market participants, guiding the economy towards optimal equilibrium paths with lower financial volatility and enhanced welfare. We reveal three novel insights: (i) Central banks, by credibly pledging future economic stabilization, can mitigate excess financial market volatility at the ZLB; (ii) Alternatively, a central bank's commitment not to stabilize the economy in the future can direct the economy towards more favorable equilibrium paths with reduced endogenous volatility at the ZLB, presenting a trade-off between future business cycle stabilization and reduced financial volatility at the ZLB; (iii) Retaining some degree of uncertainty regarding the timing of future stabilization plans strictly dominates other forms of forward guidance commitments. Finally, an examination of alternative fiscal policies reveals that measures encouraging increased investment in risky assets can stimulate economic activity at the ZLB by positively impacting aggregate household financial wealth.\"\tSeung Joo Lee\t\"Dordal i Carreras, Marc and Seung Joo Lee. \"\"Higher-Order Forward Guidance.\"\"  <i>Working Paper</i> (2024).\"\t\"Dordal i Carreras, Marc and Seung Joo Lee.\"\t<i>Working Paper</i> (2024).\tDJ_Higher_OrderFW\t\thttp://marcdordal.github.io/files/WP_Higher_order_forward_guidance.pdf\thttp://marcdordal.github.io/files/slides_Higher_order_forward_guidance.pdf\t\t\t\t\t\t\n",
      "22/02/2025\tworking_paper\tsubmitted\tEndogenous Firm Entry and the Monetary Policy Room\t\t\"We present a business cycle model featuring endogenous firm entry. Entry-induced short-run shifts in supply shape the economy’s response to both supply and demand shocks. In particular, rising aggregate demand spurs entry, expanding supply and reinforcing demand through entrants’ investment expenditures. Monetary policy influences both aggregate demand and the entry decisions of financially constrained firms, shaping cycle dynamics in economies with high entry potential. Equilibrium firm entry is characterized by the “policy room”, a sufficient statistic for monetary policy effectiveness in both the model and empirical data.\"\t\"We present a business cycle model featuring endogenous firm entry. Entry-induced short-run shifts in supply shape the economy’s response to both supply and demand shocks. In particular, rising aggregate demand spurs entry, expanding supply and reinforcing demand through entrants’ investment expenditures. Monetary policy influences both aggregate demand and the entry decisions of financially constrained firms, shaping cycle dynamics in economies with high entry potential. Equilibrium firm entry is characterized by the “policy room”, a sufficient statistic for monetary policy effectiveness in both the model and empirical data.\"\tSeung Joo Lee and Zhenghua Qi\t\"Dordal i Carreras, Marc, Seung Joo Lee, and Zhenghua Qi. \"\"Endogenous Firm Entry and the Monetary Policy 'Room'.\"\"  <i>Working Paper</i> (2025).\"\t\"Dordal i Carreras, Marc, Seung Joo Lee, and Zhenghua Qi.\"\t<i>Working Paper</i> (2025).\tDJQ_ASAD_revisited\t\thttp://marcdordal.github.io/files/WP_Firm_Entry_Supply_side_MP.pdf\thttp://marcdordal.github.io/files/slides_Firm_Entry_Supply_side_MP.pdf\t\t\t\t\t\t\n",
      "8/1/2024\tworking_paper\tsubmitted\tSelf-fulfilling Volatility and a New Monetary Policy\t\t\"We demonstrate that macroeconomic models with nominal rigidities feature multiple global solutions supporting alternative equilibria traditionally overlooked in the literature. In these equilibria, conventional Taylor rules give rise to self-fulfilling aggregate volatility, propelling the economy into crises (booms) characterized by elevated (reduced) aggregate risk. This outcome stems from the inability of conventional rules to target the expected growth rate of output, which is determined not only by the policy rate but also by the strength of the precautionary savings channel. We propose a new policy rule that targets both conventional mandates and aggregate volatility, reestablishing determinacy and achieving full stabilization.\"\t\"We demonstrate that macroeconomic models with nominal rigidities feature multiple global solutions supporting alternative equilibria traditionally overlooked in the literature. In these equilibria, conventional Taylor rules give rise to self-fulfilling aggregate volatility, propelling the economy into crises (booms) characterized by elevated (reduced) aggregate risk. This outcome stems from the inability of conventional rules to target the expected growth rate of output, which is determined not only by the policy rate but also by the strength of the precautionary savings channel. We propose a new policy rule that targets both conventional mandates and aggregate volatility, reestablishing determinacy and achieving full stabilization.\"\tSeung Joo Lee\t\"Joo Lee, Seung, and Marc Dordal i Carreras. \"\"Self-fulfilling Volatility and a New Monetary Policy.\"\"  <i>Working Paper</i> (2024).\"\t\"Joo Lee, Seung, and Marc Dordal i Carreras.\"\t<i>Working Paper</i> (2024).\tJD_sunspot\t\thttp://marcdordal.github.io/files/WP_Sunspot_risk_premium.pdf\thttp://marcdordal.github.io/files/slides_Sunspot_risk_premium.pdf\t\t\t\t\t\t\n",
      "8/1/2024\tworking_paper\tsubmitted\t\"Efficiency, Risk and the Gains from Trade in Interbank Markets\"\t\t\"We propose a model of the financial sector that captures complex relationships between highly heterogeneous agents in the market for loanable interbank funds and develops the bank-to-bank component of the macroeconomics financial transmission channel. Financial institutions trade funds due to heterogeneous capacity to provide liquidity, but trade is subject to frictions and uncertainty. The model provides a tractable framework to study the trade-off between efficiency and volatility in the financial sector, and its contribution to business cycles fluctuations.\"\t\"We propose a model of the financial sector that captures complex relationships between highly heterogeneous agents in the market for loanable interbank funds and develops the bank-to-bank component of the macroeconomics financial transmission channel. Financial institutions trade funds due to heterogeneous capacity to provide liquidity, but trade is subject to frictions and uncertainty. The model provides a tractable framework to study the trade-off between efficiency and volatility in the financial sector, and its contribution to business cycles fluctuations.\"\tMatthias Hoelzlein and Jens Orben\t\"Dordal i Carreras, Marc, Matthias Hoelzlein, and Jens Orben. \"\"Efficiency, Risk and the Gains from Trade in Interbank Markets.\"\"  <i>Working Paper</i> (2024).\"\t\"Dordal i Carreras, Marc, Matthias Hoelzlein, and Jens Orben.\"\t<i>Working Paper</i> (2024).\tDHO_Interbank\t\thttp://marcdordal.github.io/files/WP_Trade_Model_Banks.pdf\thttp://marcdordal.github.io/files/slides_Trade_Model_Banks.pdf\t\t\t\t\t\t\n",
      "8/1/2024\tworking_paper\t\t\"Gender Gap, Structural Change and Female Comparative Advantage: A Quantitative Analysis of China\"\t\t\"This paper presents a theoretical framework to reconcile the declining female labor force participation (FLFP) rate and the diverging gender gap in workforce participation in China with the expansion of the service sector and with the increasing female comparative advantage in the market sectors. We argue that two factors jointly shape the trajectory of FLFP rate and gender gap in labor force participation: (i) the interaction between structural change and female comparative advantage dynamics, and (ii) the change of female comparative advantage in the market sectors relative to home production. The framework predicts that FLFP rate drops when women have comparative advantage in diminishing sectors and vice versa, and that a rise in female comparative advantage in the market sectors narrows gender differences in labor force participation.\"\t\"This paper presents a theoretical framework to reconcile the declining female labor force participation (FLFP) rate and the diverging gender gap in workforce participation in China with the expansion of the service sector and with the increasing female comparative advantage in the market sectors. We argue that two factors jointly shape the trajectory of FLFP rate and gender gap in labor force participation: (i) the interaction between structural change and female comparative advantage dynamics, and (ii) the change of female comparative advantage in the market sectors relative to home production. The framework predicts that FLFP rate drops when women have comparative advantage in diminishing sectors and vice versa, and that a rise in female comparative advantage in the market sectors narrows gender differences in labor force participation.\"\tCassie Xiang\t\"Dordal i Carreras, Marc and Cassie Xiang. \"\"Gender Gap, Structural Change and Female Comparative Advantage: A Quantitative Analysis of China.\"\"  <i>Working Paper</i> (2024).\"\t\"Dordal i Carreras, Marc and Cassie Xiang.\"\t<i>Working Paper</i> (2024).\tDX_Gender_Gap\t\t\t\t\t\t\t\t\t\n",
      "11/1/2023\tpolicy_paper\t\te-HKD Pilot Programme\t\t\"The e-HKD Pilot Programme is a key component of the HKMA's three-rail approach in paving the way for a possible implementation of a retail central bank digital currency (CBDC). The pilot programme enables HKMA's collaboration with the industry to examine innovative use cases and maximise Hong Kong's readiness for a potential e-HKD. The Hongkong and Shanghai Banking Corporation Limited (HSBC) was one of the institutions selected to participate. Collaborating with the Hong Kong University of Science and Technology (HKUST), HSBC sought to explore possible e-HKD every-day payment use cases, focusing on programmability as a value-add feature of digital currency as well as payment rail efficiency. HSBC and HKUST constructed a one-week pilot on the HKUST campus, which included 148 students and 5 merchants.\"\t\"The e-HKD Pilot Programme is a key component of the HKMA's three-rail approach in paving the way for a possible implementation of a retail central bank digital currency (CBDC). The pilot programme enables HKMA's collaboration with the industry to examine innovative use cases and maximise Hong Kong's readiness for a potential e-HKD. The Hongkong and Shanghai Banking Corporation Limited (HSBC) was one of the institutions selected to participate. Collaborating with the Hong Kong University of Science and Technology (HKUST), HSBC sought to explore possible e-HKD every-day payment use cases, focusing on programmability as a value-add feature of digital currency as well as payment rail efficiency. HSBC and HKUST constructed a one-week pilot on the HKUST campus, which included 148 students and 5 merchants.\"\tHKUST SBM and HSBC\t\t\"Dordal i Carreras, Marc, HKUST SBM and HSBC.\"\t\tD_et_al_eHKD\t\t\t\te-HKD Pilot summary results\thttp://marcdordal.github.io/files/PP_hypothetical-e-hkd-phase-1-pilot-factsheet-en.pdf\tHKMA e-HKD Pilot Phase 1 Report\thttp://marcdordal.github.io/files/PP_HKMA_eHKD_Policy_Report.pdf\t\t\n",
      "11/1/2016\tpublished_paper\t\tInfrequent but long-lived zero lower bound episodes and the optimal rate of inflation\tAnnual Review of Economics\t\"Countries rarely hit the zero lower bound (ZLB) on interest rates, but when they do, these episodes tend to be very long-lived. These two features are difficult to incorporate jointly into macroeconomic models using typical representations of shock processes. We introduce a regime-switching representation of risk premium shocks into an otherwise standard New Keynesian model to generate a realistic distribution of ZLB durations. We discuss what different calibrations of this model imply for optimal inflation rates.\"\t\"Countries rarely hit the zero lower bound (ZLB) on interest rates, but when they do, these episodes tend to be very long-lived. These two features are difficult to incorporate jointly into macroeconomic models using typical representations of shock processes. We introduce a regime-switching representation of risk premium shocks into an otherwise standard New Keynesian model to generate a realistic distribution of ZLB durations. We discuss what different calibrations of this model imply for optimal inflation rates.\"\t\"Olivier Coibion, Yuriy Gorodnichenko and Johannes Wieland\"\t\"Dordal i Carreras, Marc, Olivier Coibion, Yuriy Gorodnichenko, and Johannes Wieland. \"\"Infrequent but long-lived zero lower bound episodes and the optimal rate of inflation.\"\" <i>Annual Review of Economics</i> 8 (2016): 497-520.\"\t\"Dordal i Carreras, Marc, Olivier Coibion, Yuriy Gorodnichenko, and Johannes Wieland.\"\t<i>Annual Review of Economics</i> 8 (2016): 497-520.\tDCG_Infreq_ZLB\thttps://www.annualreviews.org/doi/abs/10.1146/annurev-economics-080315-015306\thttp://marcdordal.github.io/files/WP_Infreq_ZLB.pdf\thttp://marcdordal.github.io/files/slides_Infreq_ZLB.pdf\t\"VOX-EU, CEPR Policy Portal article\"\t\"https://cepr.org/voxeu/columns/infrequent-long-lived-zero-bound-episodes-and-optimal-rate-inflation#:~:text=policy%20Monetary%20Policy-,Infrequent%20but%20long%2Dlived%20zero%2Dbound%20episodes%20and,the%20optimal%20rate%20of%20inflation&text=Models%20that%20estimate%20optimal%20inflation,lack%20of%20historical%20data%20available.\"\t\t\t\t\n"
     ]
    }
   ],
   "source": [
    "!cat publications.tsv\n",
    "# !type publications.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import pandas\n",
    "\n",
    "We are using the very handy pandas library for dataframes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import TSV\n",
    "\n",
    "Pandas makes this easy with the read_csv function. We are using a TSV, so we specify the separator as a tab, or `\\t`.\n",
    "\n",
    "I found it important to put this data in a tab-separated values format, because there are a lot of commas in this kind of data and comma-separated values can get messed up. However, you can modify the import statement, as pandas also has read_excel(), read_json(), and others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnicodeDecodeError",
     "evalue": "'utf-8' codec can't decode byte 0x92 in position 9807: invalid start byte",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[1;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[0m publications \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpublications.tsv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msep\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m publications\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:933\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    930\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    932\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1235\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1232\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1234\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:75\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     72\u001b[0m     kwds\u001b[38;5;241m.\u001b[39mpop(key, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     74\u001b[0m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m ensure_dtype_objs(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m---> 75\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     79\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:544\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:633\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:847\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\_libs\\parsers.pyx:1952\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mUnicodeDecodeError\u001b[0m: 'utf-8' codec can't decode byte 0x92 in position 9807: invalid start byte"
     ]
    }
   ],
   "source": [
    "publications = pd.read_csv(\"publications.tsv\", sep=\"\\t\", header=0)\n",
    "publications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escape special characters\n",
    "\n",
    "YAML is very picky about how it takes a valid string, so we are replacing single and double quotes (and ampersands) with their HTML encoded equivilents. This makes them look not so readable in raw format, but they are parsed and rendered nicely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "html_escape_table = {\n",
    "    \"&\": \"&amp;\",\n",
    "    '\"': \"&quot;\",\n",
    "    \"'\": \"&apos;\"\n",
    "    }\n",
    "\n",
    "def html_escape(text):\n",
    "    \"\"\"Produce entities within text.\"\"\"\n",
    "    return \"\".join(html_escape_table.get(c,c) for c in text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete existing markdown files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The folder _published_papers does not exist or cannot be found.\n",
      "The folder _policy_papers does not exist or cannot be found.\n",
      "The folder _working_papers does not exist or cannot be found.\n",
      "The folder _works_in_progress does not exist or cannot be found.\n",
      "The folder _resting_works does not exist or cannot be found.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Replace these with the actual folder paths you want to clear.\n",
    "# base_path = 'C:/Users/marcd_ncckl9u/Documents/GitHub/marcdordal.github.io'\n",
    "base_path = 'C:/Users/PORTATIL/OneDrive/Documents/GitHub/marcdordal.github.io'\n",
    "folder_names = ['_published_papers', '_policy_papers', '_working_papers', '_works_in_progress', '_resting_works']\n",
    "\n",
    "# Loop through each folder path\n",
    "for folder in folder_names:\n",
    "    # Construct folder path\n",
    "    folder_path = base_path + \"/\" + folder\n",
    "    # Check if the folder exists\n",
    "    if os.path.exists(folder_path):\n",
    "        # Remove all contents of the folder\n",
    "        for filename in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, filename)\n",
    "            try:\n",
    "                if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                    os.unlink(file_path)  # Removes files and links\n",
    "                elif os.path.isdir(file_path):\n",
    "                    shutil.rmtree(file_path)  # Removes subdirectories\n",
    "            except Exception as e:\n",
    "                print(f'Failed to delete {file_path}. Reason: {e}')\n",
    "    else:\n",
    "        print(f'The folder {folder} does not exist or cannot be found.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the markdown files\n",
    "\n",
    "This is where the heavy lifting is done. This loops through all the rows in the TSV dataframe, then starts to concatentate a big string (```md```) that contains the markdown for each type. It does the YAML metadata first, then does the description for the individual page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'publications' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m row, item \u001b[38;5;129;01min\u001b[39;00m \u001b[43mpublications\u001b[49m\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m      4\u001b[0m     md_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(item\u001b[38;5;241m.\u001b[39mpub_date) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m item\u001b[38;5;241m.\u001b[39murl_slug \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.md\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m      5\u001b[0m     html_filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(item\u001b[38;5;241m.\u001b[39mpub_date) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m item\u001b[38;5;241m.\u001b[39murl_slug\n",
      "\u001b[1;31mNameError\u001b[0m: name 'publications' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "for row, item in publications.iterrows():\n",
    "    \n",
    "    md_filename = str(item.pub_date) + \"-\" + item.url_slug + \".md\"\n",
    "    html_filename = str(item.pub_date) + \"-\" + item.url_slug\n",
    "    year = item.pub_date[:4]\n",
    "    \n",
    "    ## YAML variables\n",
    "    \n",
    "    md = \"---\\ndate: \" + str(item.pub_date) + '\\n'\n",
    "    \n",
    "    if item.status == \"published_paper\":\n",
    "        md += \"\"\"collection: published_papers\"\"\"\n",
    "        md += \"\"\"\\npermalink: /published_paper/\"\"\" + html_filename\n",
    "            \n",
    "    elif item.status == \"working_paper\":\n",
    "        md += \"\"\"collection: working_papers\"\"\"\n",
    "        md += \"\"\"\\npermalink: /working_paper/\"\"\" + html_filename\n",
    "            \n",
    "    elif item.status == \"policy_paper\":\n",
    "        md += \"\"\"collection: policy_papers\"\"\"\n",
    "        md += \"\"\"\\npermalink: /policy_paper/\"\"\" + html_filename\n",
    "            \n",
    "    elif item.status == \"work_in_progress\":\n",
    "        md += \"\"\"collection: works_in_progress\"\"\"\n",
    "        md += \"\"\"\\npermalink: /work_in_progress/\"\"\" + html_filename\n",
    "            \n",
    "    elif item.status == \"resting_work\":\n",
    "        md += \"\"\"collection: resting_works\"\"\"\n",
    "        md += \"\"\"\\npermalink: /resting_work/\"\"\" + html_filename\n",
    "    \n",
    "    if len(str(item.status2)) > 5:\n",
    "        md += \"\\nstatus2: '\" + html_escape(item.status2) + \"'\"\n",
    "    \n",
    "#     md = \"---\\ntitle: \\\"\"   + item.title + '\"\\n'\n",
    "\n",
    "    md += \"\\ntitle: \\\"\"   + item.title + '\"'\n",
    "\n",
    "    if len(str(item.venue)) > 5:\n",
    "        md += \"\\nvenue: '\" + html_escape(item.venue) + \"'\"\n",
    "    \n",
    "    if len(str(item.excerpt)) > 5:\n",
    "        md += \"\\nexcerpt: '\" + html_escape(item.excerpt) + \"'\"\n",
    "        md += \"\\ncustom_excerpt: \" + \"'true'\"\n",
    "    \n",
    "    if len(str(item.abstract)) > 5:\n",
    "        md += \"\\nabstract: '\" + html_escape(item.abstract) + \"'\"\n",
    "        \n",
    "    if len(str(item.coauthors)) > 5:\n",
    "        md += \"\\ncoauthors: '\" + html_escape(item.coauthors) + \"'\"\n",
    "    \n",
    "    if len(str(item.citation)) > 5:\n",
    "        md += \"\\ncitation: '\" + html_escape(item.citation) + \"'\"\n",
    "    \n",
    "    if len(str(item.cv_citation_authors)) > 5:\n",
    "        md += \"\\ncv_citation_authors: '\" + html_escape(item.cv_citation_authors) + \"'\"\n",
    "        \n",
    "    if len(str(item.cv_citation_other)) > 5:\n",
    "        md += \"\\ncv_citation_other: '\" + html_escape(item.cv_citation_other) + \"'\"\n",
    "    \n",
    "    if len(str(item.url_slug)) > 5:\n",
    "        md += \"\\nurl_slug: '\" + html_escape(item.url_slug) + \"'\"\n",
    "    \n",
    "    if len(str(item.pub_paper_url)) > 5:\n",
    "        md += \"\\npubpaperurl: '\" + item.pub_paper_url + \"'\"\n",
    "    \n",
    "    if len(str(item.wp_paper_url)) > 5:\n",
    "        md += \"\\nwppaperurl: '\" + item.wp_paper_url + \"'\"\n",
    "    \n",
    "    if len(str(item.slides_url)) > 5:\n",
    "        md += \"\\nslidesurl: '\" + item.slides_url + \"'\"\n",
    "     \n",
    "    for i in range(3):\n",
    "        opt_url = item[f'opt{i}_url']\n",
    "        opt_text = item[f'opt{i}_text']\n",
    "        \n",
    "        if len(str(opt_url)) > 5:\n",
    "            md += \"\\n\" f'opt{i}text' \": '\" + opt_text + \"'\"\n",
    "            md += \"\\n\" f'opt{i}url' \": '\" + opt_url + \"'\"\n",
    "    \n",
    "    md += \"\\n---\\n\"\n",
    "    \n",
    "    ## Markdown description for individual page\n",
    "        \n",
    "    if len(str(item.abstract)) > 5:\n",
    "        md += \"Abstract: \" + html_escape(item.abstract) + \"\\n\\n\"\n",
    "    \n",
    "    if len(str(item.pub_paper_url)) > 5:\n",
    "        md += \"[[Publication](\" + item.pub_paper_url + \"){: target=\\\"_blank\\\" }] \" \n",
    "    \n",
    "    if len(str(item.wp_paper_url)) > 5:\n",
    "        md += \"[[Draft](\" + item.wp_paper_url + \"){: target=\\\"_blank\\\" }] \" \n",
    "\n",
    "    if len(str(item.slides_url)) > 5:\n",
    "        md += \"[[Slides](\" + item.slides_url + \"){: target=\\\"_blank\\\" }] \" \n",
    "    \n",
    "    for i in range(3):\n",
    "        opt_url = item[f'opt{i}_url']\n",
    "        opt_text = item[f'opt{i}_text']\n",
    "        \n",
    "        if len(str(opt_url)) > 5:\n",
    "            md += \"\\n[[\" + opt_text + \"](\" + opt_url + \"){: target=\\\"_blank\\\" }] \"     \n",
    "    \n",
    "    \n",
    "    if len(str(item.citation)) > 5:\n",
    "        if len(str(item.pub_paper_url)) > 5:\n",
    "            md += \"\\n\\nRecommended citation: \" + item.citation + \" \" + item.pub_paper_url\n",
    "        elif len(str(item.wp_paper_url)) > 5:\n",
    "            md += \"\\n\\nRecommended citation: \" + item.citation + \" \" + item.wp_paper_url\n",
    "        else:\n",
    "            md += \"\\n\\nRecommended citation: \" + item.citation\n",
    "    \n",
    "    md_filename = os.path.basename(md_filename)\n",
    "    \n",
    "    \n",
    "    ## Save markdown file into corresponding GitHub folder\n",
    "    if item.status == \"published_paper\":\n",
    "        with open(\"../_published_papers/\" + md_filename, 'w') as f:\n",
    "            f.write(md)\n",
    "            \n",
    "    elif item.status == \"working_paper\":\n",
    "        with open(\"../_working_papers/\" + md_filename, 'w') as f:\n",
    "            f.write(md)\n",
    "            \n",
    "    elif item.status == \"policy_paper\":\n",
    "        with open(\"../_policy_papers/\" + md_filename, 'w') as f:\n",
    "            f.write(md)\n",
    "            \n",
    "    elif item.status == \"work_in_progress\":\n",
    "        with open(\"../_works_in_progress/\" + md_filename, 'w') as f:\n",
    "            f.write(md)\n",
    "            \n",
    "    elif item.status == \"resting_work\":\n",
    "        with open(\"../_resting_works/\" + md_filename, 'w') as f:\n",
    "            f.write(md)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These files are in the publications directory, one directory below where we're working from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2024-DHO_Interbank.md\n",
      "2024-DJQ_ASAD_revisited.md\n",
      "2024-DJ_Bank_Panics.md\n",
      "2024-DJ_Higher_OrderFW.md\n",
      "2024-DKJG_eHKD_pilot.md\n",
      "2024-DX_Gender_Gap.md\n",
      "2024-JD_sunspot.md\n",
      "2024-JD_term_structure_theory.md\n",
      "2025-JD_term_structure_theory.md\n"
     ]
    }
   ],
   "source": [
    "!ls ../_working_papers/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---\n",
      "date: 22/02/2025\n",
      "collection: working_papers\n",
      "permalink: /working_paper/22/02/2025-JD_term_structure_theory\n",
      "status2: 'submitted'\n",
      "title: \"Yield-Curve Control Policy under Inelastic Financial Markets\"\n",
      "excerpt: 'We develop a New Keynesian framework that incorporates the term structure of financial markets, emphasizing the role of government and central bank balance sheet composition in monetary policy transmission. Our model accounts for microfounded market segmentation across asset classes and maturities based on finite and estimable asset demand elasticities. We show that unconventional policy interventions, such as large-scale asset purchase programs and yield-curve control policies, effectively stabilize the economy during normal periods and at the zero lower bound, albeit by extending ZLB episodes and reducing the efficacy of future short-term rate adjustments.'\n",
      "custom_excerpt: 'true'\n",
      "abstract: 'We develop a New Keynesian framework that incorporates the term structure of financial markets, emphasizing the role of government and central bank balance sheet composition in monetary policy transmission. Our model accounts for microfounded market segmentation across asset classes and maturities based on finite and estimable asset demand elasticities. We show that unconventional policy interventions, such as large-scale asset purchase programs and yield-curve control policies, effectively stabilize the economy during normal periods and at the zero lower bound, albeit by extending ZLB episodes and reducing the efficacy of future short-term rate adjustments.'\n",
      "coauthors: 'Seung Joo Lee'\n",
      "citation: 'Joo Lee, Seung, and Marc Dordal i Carreras. &quot;A Unified Theory of the Term-Structure and Monetary Stabilization.&quot;  <i>Working Paper</i> (2025).'\n",
      "cv_citation_authors: 'Joo Lee, Seung, and Marc Dordal i Carreras.'\n",
      "cv_citation_other: '<i>Working Paper</i> (2025).'\n",
      "url_slug: 'JD_term_structure_theory'\n",
      "wppaperurl: 'http://marcdordal.github.io/files/WP_Term_Structure_Theory.pdf'\n",
      "slidesurl: 'http://marcdordal.github.io/files/slides_Term_Structure_Theory.pdf'\n",
      "---\n",
      "Abstract: We develop a New Keynesian framework that incorporates the term structure of financial markets, emphasizing the role of government and central bank balance sheet composition in monetary policy transmission. Our model accounts for microfounded market segmentation across asset classes and maturities based on finite and estimable asset demand elasticities. We show that unconventional policy interventions, such as large-scale asset purchase programs and yield-curve control policies, effectively stabilize the economy during normal periods and at the zero lower bound, albeit by extending ZLB episodes and reducing the efficacy of future short-term rate adjustments.\n",
      "\n",
      "[[Draft](http://marcdordal.github.io/files/WP_Term_Structure_Theory.pdf){: target=\"_blank\" }] [[Slides](http://marcdordal.github.io/files/slides_Term_Structure_Theory.pdf){: target=\"_blank\" }] \n",
      "\n",
      "Recommended citation: Joo Lee, Seung, and Marc Dordal i Carreras. \"A Unified Theory of the Term-Structure and Monetary Stabilization.\"  <i>Working Paper</i> (2025). http://marcdordal.github.io/files/WP_Term_Structure_Theory.pdf\n"
     ]
    }
   ],
   "source": [
    "!cat ../_working_papers/2025-JD_term_structure_theory.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
